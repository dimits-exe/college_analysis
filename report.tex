\documentclass[10pt, a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[greek, english]{babel}
\usepackage{alphabeta}
\usepackage{libertine}
\usepackage{graphicx}
\usepackage{biblatex}[sorting=nty] % sort alphabetically
\usepackage[table]{xcolor}
\usepackage{mathptmx} % Times New Roman
\usepackage{makecell}
\usepackage{setspace}

\pagenumbering{arabic}
\onehalfspacing % Set line spacing to 1.5
\graphicspath{ {./resources/} }
\addbibresource{refs.bib}

\def\code#1{\texttt{#1}}

\title{\Huge A Comprehensive Study on US College Admissions  }

\author{\large Tsirmpas Dimitris\\Athens University of Economics and Business\\Department of Informatics}


\begin{document}
	
	\begin{titlepage}
		\maketitle
		\begin{center}
					
			\includegraphics[width=1\textwidth]{aueb_logo.jpg}
			
			\large Athens University of Economics and Business
			
			\large Department of Statistics
			
			\large Greece
		\end{center}
	
	\end{titlepage}
	
	\tableofcontents
	\newpage
	
	\section{Abstract}
	US College Admissions have and continue to be a subject of great debate among scholars and analysts. Such educational institutions have an interest in selecting the most qualified applicants using limited data, while the applicants themselves often protest admission requirements, especially those deemed discriminatory in nature. In this study we discover relationships between the candidate's gender and previous program and their overall test scores. We also identify a positive correlation between test scores, which we attribute to a common, unknown variable called "Competence".
	
	
	\section{Introduction}
	
	The aim of this study is to investigate possible links and relationships between a candidate's characteristics and their performance in multiple standardized tests. We employ a random sample of 200 students who applied to continue their studies in their respective universities. Their application consisted of three standardized tests testing their skills and knowledge in mathematics, social studies and creative writing. An overview of the data contained can be found in Table \ref{tab::dataset}. 
	
	The data and replication code can be found in our GitHub repository \footnote{\url{https://github.com/dimits-exe/college_analysis}}. We make the assumption that the dataset has been acquired through random, unbiased sampling. We also make the assumption that the records using different IDs represent different students (and as such are considered independent samples).
	
	The study is structured as follows: In Section \ref{sec::exploratory} we make general observations about our data, identify key relationships and form our first hypotheses. We follow up these hypotheses in Section \ref{sec::var_cors} with robust analyses and in Section \ref{sec::models} by employing various regression models. Section \ref{sec::conclusions} features an overview and discussion about our findings. Finally, we include graphs, tables and supporting documents in the report's Addendum (Section \ref{sec::addendum}).
	
	For the sake of brevity we will refer to the following statistical tests with the following acronyms: Shapiro Wilk (S-W) and Lilliefors (Kolmogorov-Smirnov) (K-S) normality tests, Bartlett (Bart) and Levene's (Lev) tests of homogeneity of variances, Durbin Watson (D-W) autocorrelation test, Wilcoxon (Wil) and Kruskal-Wallis (K-W) rank sum tests.
	
	All the test, images and graphs were executed and built using \code{R $4.11$} and the \code{haven, nortest, car, psych, nortest, sjPlot} and \code{stargazer} libraries.
	
	\section{Exploratory Analysis}
	\label{sec::exploratory}
	
	\begin{table}
		\centering
		\rowcolors{2}{gray!25}{white}
		\begin{tabular}
			{ |p{1cm} p{1cm} p{5cm} p{3cm}| }
			\hline
			\textbf{Name} & \textbf{Type} & \textbf{Description} & \textbf{Range}\\
			\hline
			Id  & Nominal & The student's ID & [1-200] \\
			Gender  & Binary & The student's gender & \{male, female\} \\
			Race  & Nominal & The student's race & \{white, latin-american, asian, african-american\} \\
			Schtype  & Binary & The type of the student's secondary education institution & \{public, private\} \\
			Prog  & Nominal & The student's previous study cycle  & \{general, vocation, academic \} \\
			Write  & Numeric & The grade on the writing test  & [0-100] \\
			Math  & Numeric & The grade on the mathematics test  & [0-100] \\
			Socst  & Numeric & The grade on the social studies test & [0-100] \\
			\hline
		\end{tabular}
		\caption{An overview of the data used in this study.}
		\label{tab::dataset}
	\end{table}
	
	The numerical variables contained in the dataset are described in Table \ref{tab::summary_stats} and their distribution can be seen in Figure . We observe that they are all almost symmetrical ($-0.5 \leq skew \leq 0.5$), and feature moderate negative (right) skewness with a mean/median hovering just above a score of 50. This indicates most students score around the baseline, most of which pass the exams with a mediocre grade.
	
	\begin{table}
		\centering
		\rowcolors{2}{gray!25}{white}
		\begin{tabular}
			{ |p{1cm} p{0.5cm} p{0.7cm} p{0.5cm} p{1cm} p{0.7cm} p{0.5cm} p{0.5cm} p{0.5cm} p{0.5cm} p{0.5cm}| }
			\hline
			\textbf{Var.} & \textbf{Obs.} & \textbf{Mean} & \textbf{Std} & \textbf{Median} & \textbf{Trim} & \textbf{Min} & \textbf{Max} & \textbf{Skew} & \textbf{Kurt} & \textbf{SE}\\
			\hline
			Write & $200$ & $52.77$ & $9.48$ & $54$ & $53.36$ & $31$ & $67$ & $-0.47$ & $-0.78$ & $0.67$ \\
			Math & $200$ & $52.65$ & $9.37$ & $52$ & $52.33$ & $33$ & $75$ & $0.28$ & $-0.69$ & $0.66$ \\
			Socst & $200$ & $52.41$ & $10.74$ & $52$ &$ 52.99$ & $26$ & $71$ & $-0.38$ & $-0.57$ & $0.76$ \\
			\hline
		\end{tabular}
		\caption{Summary statistics on the numerical data used in the study.}
		\label{tab::summary_stats}
	\end{table}

	\begin{figure}
		\includegraphics[width=8cm]{density_plots.png}
		\centering
		\caption{Plots displaying the test score's distributions in our dataset.}
		\label{fig::test_distribution}
	\end{figure}
		
	We next study relationships between the candidates' characteristics (not including test scores). We run $\chi^2$ tests on \textit{Gender, Race, Program} and \textit{School Type}. The only statistically significant relationship in our dataset is between \textit{School Type} and \textit{Program} ($p = 0.015$), which can be seen in the Addendum.
	
	Finally, we study the relationships between the three subjects. There is a very statistically significant ($p < 0.0001$), positive (Pearson's $r > 0.5$) relationship between all three subjects. This could be indicative of either one of the variables influencing the other, or an unknown, interfering variable which positively affects the three test scores. We hypothesize the latter, as the existence of such a variable indicating the student's general competence in tests makes intuitive sense. We will refer to this potential, unknown variable as \textit{"Competence"} in this report.
	
	Since the three subjects are strongly correlated we can explore correlations between the rest of the factors and any of the tests, assuming that a correlation with one strongly indicates with the other two as well. 
	
	We notice a probable correlation between gender and writing scores, as shown in Figure \ref{fig::write_gender}, as well as between the student's program and writing scores, as shown in Figure \ref{fig::write_prog}.
	
	\begin{figure}
		\includegraphics[width=6cm]{write_genre_boxplot.png}
		\centering
		\caption{Boxplot displaying the writing score by gender.}
		\label{fig::write_gender}
	\end{figure}
	
	\begin{figure}
		\includegraphics[width=6cm]{write_prog_boxplot.png}
		\centering
		\caption{Boxplot displaying the writing score by current program. Notice the significant differences in means.}
		\label{fig::write_prog}
	\end{figure}
	
	\section{Variable correlations}
	\label{sec::var_cors}
	
	\subsection{Writing scores influenced by gender}
	Our exploratory analysis indicated a possible discrepancy between the results of writing tests between men and women, as well as between different programs. We thus investigate whether gender and the candidate's current program play a role in writing test score.
	
	% parencite displays as cite for some reason
	We begin by verifying the preconditions necessary for the standard t-test in order to compare the genders' scores. We compute the mean differences of the samples by subtracting the global mean by the women's scores (\textcite{means}), and conclude they are not normal (S-W, $p = 0.0024$). The variances are not homogeneous (Lev $p = 0.0022 < 0.05$, Bart $p = 0.0019 < 0.05$), although this should not dissuade us from using a parametric t-test since the relatively large sample size ($N=200$) and balanced groups ($N_{women} = 109, N_{men} = 91$) means the precondition's violation is not significant (\textcite{variances}). We will use a non-parametric test since the distribution of the differences do not have a normal kurtosis (Jarque-Bera Normality Test (\textcite{jarque}), $p=0.026$), and thus their mean is not suitable.
	
	We conclude there is a statistically significant difference between the writing scores of men and women (Wil $p = 0.0009$) with women having on average 5 more score than men (Wil with $H_a = less$, $p = 0.0004$).
	
	
	\subsection{Writing scores influenced by previous program}
	We will now verify the preconditions for the parametric ANOVA test in order to test which programs are correlated with the writing tests' scores. The variances of the residuals are homogeneous (Lev $p = 0.1873$, Bartlett's test $p = 0.27$), but not normal (S-W, $p = 0.002$). We will thus use a non-parametric test.
	
	We discover there is a statistically significant difference between the groups (K-S, $p=4e-08$). We can consult the boxplots in Figure \ref{fig::write_prog}, where we observe significant differences between all three groups.
	
	
	\section{Predictive / descriptive models}
	\label{sec::models}
	
	\subsection{Building the base models}
	Having confirmed our hypotheses regarding the relationships between the various variables and the writing test scores, we attempt to build a model which will estimate a candidate's math and social study scores, testing our hypothesis that the three scores are influenced by the same external factors. 
	
	Since there seem to be strong correlations between most independent variables and the writing scores, and since we already established a strong correlation between the scores themselves (attributed to the candidate's \textit{"Competence"}), we will be using a simple, Ordinary Least Squares (OLS) model.
	
	We initially build an OLS model estimating the writing scores which involves all the available variables. This model exhibits a good fit, being able to explain almost half of the variance in our data ($R^2_{adj} = 0.4861, BIC=1377$). However, it exhibits low confidence about the candidate's race and no confidence about the school type ($p=0.6502$). In order to build an optimal model, we consider dropping these two variables. Dropping the candidate's race along with the school type leads to a slight decrease of $R^2_{adj} = 0.4753$. Dropping only the school type on the other hand leads to an improved $R^2_{adj} = 0.488, BIC=1372, F= 24.729 p=<0.001$. We use BIC to compare our models as they are descriptive, not predictive.
	
	We briefly check the pre-conditions for linear regression. The residuals are not sufficiently normal (S-W $p = 0.0125$, Lillie $p=0.0241$), although this does not discourage us, since linear models have been robust against normality assumption violations for large samples ($N\geq 100$) \cite{ols_linear}. The residuals are homogeneous given a $95\%$ confidence level (Lev $p = 0.081$, Bart $p = 0.05368$) and non-correlated (D-W, $p=0.26$). There are also no sings of multicollinearity. While some outliers exist, none of them are considered anomalies.
	
	An issue with our model is that there doesn't seem to be a strong linear relationship (see Addendum). Our data however are exclusively either categorical variables, or numeric variables following the same scale (0-100 score) and distribution (see Section \ref{sec::exploratory}). Thus, our model performs worse when mathematical transformations such as logarithms are applied to our data.
	%
	\input{lm_math_peeking.tex}
	%
	The resulting model can be found in Table \ref{tab::lm_math_peeking} and can be interpreted as such: 
	\begin{itemize}
		\item If a candidate is female, Hispanic, has a generic background, and completely failed her other tests (writing score = social studies score = 0), her score in the math test would be $20.334$. 
		\item For every point scored in the writing test, the math score would improve by 0.4 points.
		\item For every point scored in the social studies test, by 0.167 points.
		\item If the candidate is male, he will score an average of $-2.8$ less points.
		\item Depending on his background the candidate will either on average score $3.788$ (academic) or $-0.375$ (vocational) additional points.
		\item Finally, depending on his race a candidate will score an average of $5$ (Asian), $-1.1$ (African American) or $0.308$ additional points.
	\end{itemize}

	We now follow the same procedure for the social studies test. We fit a model involving all available variables, which explains our sample to a decent degree ($R^2_{adj} = 0.4581, BIC=1452$). The residuals are not sufficiently normal (S-W $p = 0.008$, Lillie $p=0.061$), homogeneous (Lev $p = 0.452$, Bart $p = 0.635$) and non-correlated (D-W, $p=0.848$). There appears to be no multicollinearity, the residuals are linear and there are no anomalies. Since the normality assumption can be waived because of our large sample size, we assume all preconditions are met.
	
	As mentioned above, this model is reliant on the math and especially on the writing scores, while the rest of the variables are mostly not statistically significant. We thus employ a stepwise procedure in order to eliminate variables deemed statistically insignificant while retaining, or increasing our models goodness of fit. A summary of the resulting model can be found in Table \ref{tab::lm_socst_peeking} and can be interpreted in a similar manner to the model above.
	
	The results seem to verify our main hypothesis, that the test scores are predominately caused by the unknown "Competence" value. While other variables such as the candidate's past program, have a statistically significant influence in our model, we can see that the model's estimations are consistently based on the writing and other-lesson's test scores. We can additionally rule out this relationship being a result of multi-co-linearity between the test variables, as seen in the previous auto-correlations tests.
	%
	\input{lm_socst_peeking.tex}\unskip
	%
	\subsection{Identifying test score causation}
	
	The results above, although encouraging, do not rule out the alternative hypothesis we posed in the Introduction of this report, that the definite correlation between the test scores is caused by one of the test scores themselves influencing the others. We thus repeat the experiments of the previous subsection while omitting the writing scores. If our alternative hypothesis was correct we would expect our models to no longer have a good performance, while having a much smaller statistical significance on the other lesson's model.
	
	We begin by constructing an OLS regression model which tries to estimate the math score by considering the candidate's characteristics and their score in the social studies test. Our initial model including all the variables performs adequately $R^2_{adj} = 0.3999, BIC=1404$. By employing a backwards procedure we end up with our final model with a total $R^2_{adj} = 0.4022, BIC=1395$, found in Table \ref{tab::lm_math_nopeeking}.
	
	We verify all the necessary preconditions; the residuals appear to be normal (S-W $p = 0.863$, Lillie $p=0.885$), homogeneous (Lev $p = 0.431$, Bart $p = 0.42$) and non-correlated (D-W, $p=0.57$). There appears to be no multicollinearity, the residuals are marginally linear and there are no anomalies.
	%
	\input{lm_math_nopeeking.tex}
	%
	We repeat the procedure for estimating the social study test scores without relying on the writing tests. Our base model, which considers all the available variables, displays a $R^2_{adj} = 0.3393, BIC=1478$, which is considerably worse than the respective math model. This may be because of the previously mentioned reliance on the writing scores, which are no longer available to the model. Additionally, similarly to the previous models, the model lacks confidence in almost all other variables; the only statistical significant variable other than the math scores ($p_{math} = 4.25e-09$) and the Constant ($p_{Intercept} = 5.27e-08$) is the candidate's Program ($p_{progvocation} = 0.0283$).
	
	Because of the many possible variables that are candidates for removal we can again employ a stepwise model selection algorithm. The best model by BIC (Table \ref{tab::lm_socst_nopeeking}) keeps only the math and program variables (as expected) but overall explains less of the data ($R^2_{adj} = 0.3383, BIC=1457$).
	
	We again verify the preconditions necessary for the linear regression model. The residuals appear to not be normal (S-W $p = 0.03985$, Lillie $p=0.02452$), homogeneous (Lev $p = 0.1413$, Bart $p = 0.2216$) and the variables are non-correlated (D-W, $p=0.984$). There appears to be no multicollinearity, the residuals are linear and there are no anomalies. We consider the model sound  despite the non-normality of the residuals because of our large sample size.
	%
	\input{lm_socst_nopeeking.tex}
	%
	These findings appear to contradict our alternative hypothesis. While our models' performance certainly degraded, they still achieve comparable results, with their performance loss being explained by the degree to which \textit{"Competence"} can be measured. In other words, this unknown variable can be approximated more accurately by considering both other tests, instead of just one. This is further proof that our initial hypothesis appears to be correct.

	\section{Conclusions \& Discussion}
	\label{sec::conclusions}
	
	In this report we studied extensively the relationships between different characteristics of US university applicants. We observed that characteristics such as race, gender, schooling and previous programs are uncorrelated, with the exception of a positive relationship between private schooling and academic background. We verified that female candidates score on average higher than males in writing tests, as well as that the candidate's previous program influences their writing test scores. 
	
	Additionally, we observed a definite positive correlation between candidate test scores. We hypothesized this was the product of an unknown variable, called \textit{"Competence"} which similarly influences all test scores and posed an alternative hypothesis stating that one of the test scores was the cause of the correlation. We show evidence of this variable's existence by constructing linear regression models and disprove the alternative hypothesis by constructing such models without access to the common variable \textit{Writing Score}.
	
	This study highlights that other test scores are consistently robust and important variables when attempting to assess future test scores, even if these test scores are on different disciplines (such as social studies and mathematics). Further research is warranted to check whether past test scores can be used to consistently predict candidate performance, as well as from how far in the past, and within which disciplines these scores would be useful.
	
	We note that these findings are only representative for our sample. Our statistical models were used exclusively as explanatory models and should not be used for prediction. We also note that the relationships presented in this report are only representative of our sample, and should not be generalized for the general population. Finally, we warn against extrapolating any relationships from our tests, since they only imply a correlation, not necessarily causation.
	
	
	\section{References}
	\printbibliography[heading=none]
	
	\newpage
	\section{Addendum}
	\label{sec::addendum}
	
	\subsection{Exploratory Analysis}
	In this section we include tables and figures which were used in the exploratory analysis of the data in the Introduction. 
	
	\begin{table}
		\centering
		\rowcolors{2}{gray!25}{white}
		\begin{tabular}
			{ |p{2.5cm} | p{2.5cm} | p{2.5cm}  | p{2.5cm} | }
			\hline
			& \textbf{Writing} & \textbf{Math} & \textbf{Social Studies} \\
			\hline
			\textbf{Writing} & \cellcolor{darkgray} & \cellcolor{darkgray} & \cellcolor{darkgray} \\
			\hline
			\textbf{Math} & \makecell{$0.62$\\ $0.000$ ****} & \cellcolor{darkgray} & \cellcolor{darkgray}\\
			\hline
			\textbf{Social Studies} & \makecell{$0.60$\\ $0.000$ ****} & \makecell{$0.54$\\ $0.000$**** \\} &\cellcolor{darkgray}\\
			\hline
		\end{tabular}
		\caption{Pearson's correlation coefficient (Holm's correction) between the tests and their ps. Stars indicate significance scores: $>1$:'', $0.1$:'*', $0.01$: '**', $0.001$: '***', $<0.0001$: '****'.}
		\label{tab::corr}
	\end{table}

	\begin{table}
		\centering
		\rowcolors{2}{gray!25}{white}
		\begin{tabular}
			{ |p{2cm} | p{1.2cm} p{1.2cm} p{1.2cm} | p{1.2cm} | }
			\hline
			\multicolumn{5}{|c|}{\textbf{Previous Program}}\\
			\hline
			\textbf{School Type} & \textbf{general} & \textbf{academic} & \textbf{vocation} & \textbf{Total}\\
			\hline
			\textbf{public} & \makecell{39 \\ $23.2\%$} & \makecell{81 \\ $48.2\%$} & \makecell{48 \\ $28.6\%$} & \makecell{168 \\ $100\%$} \\
			\textbf{private} & \makecell{6 \\ $18.8\%$} & \makecell{24 \\ $75\%$} & \makecell{2 \\ $6.2\%$} & \makecell{32 \\ $100\%$}\\
			\hline
			\textbf{Total} & \makecell{45 \\ $22.5\%$} & \makecell{105 \\ $52.5\%$} & \makecell{50 \\ $25\%$} & \makecell{200 \\ $100\%$}\\
			\hline
		\end{tabular}
		\caption{$\chi^2$ test between \textit{School Type} and \textit{Program}. Notice the overwhelming majority of candidates who attended private schools having an academic background prior to applying.}
		\label{tab::chisq}
	\end{table}
	
	\begin{figure}[h]
		\includegraphics[width=8cm]{write_schtyp_boxplot.png}
		\centering
		\caption{Boxplot displaying the writing score by school type.}
		\label{fig::write_schtyp_boxplot}
	\end{figure}
	
	\begin{figure}[h]
		\includegraphics[width=8cm]{write_race_boxplot.png}
		\centering
		\caption{Boxplot displaying the writing score by candidate race.}
		\label{fig::write_race_boxplot}
	\end{figure}
	
	
	\subsection{OLS model preconditions}
	
	In order to visually confirm the normal distribution of the model's residuals, we plot their boxplots for each of the 4 quantiles. We expect these boxplots to resemble those of the normal distribution, centered on $y=0$ and with 95\% of their values not going above/below the $y=1.95$ and $y=-1.95$ respectively. Figures \ref{fig::lm_math_boxplot}, \ref{fig::lm_socst_boxplot} show models including the writing scores. Figures \ref{fig::lm_math_nopeeking_boxplot}, \ref{fig::lm_socst_nopeeking_boxplot} show models including only the other lesson's scores.
	
	\begin{figure}
		\includegraphics[width=8cm]{lm_math_residual_boxplot.png}
		\centering
		\caption{The normalized residuals of the math model plotted for each of the 4 quantiles.}
		\label{fig::lm_math_boxplot}
	\end{figure}

	\begin{figure}
		\includegraphics[width=8cm]{lm_socst_residual_boxplot.png}
		\centering
		\caption{The normalized residuals of the social studies model plotted for each of the 4 quantiles. }
		\label{fig::lm_socst_boxplot}
	\end{figure}

	\begin{figure}
		\includegraphics[width=8cm]{lm_math_nopeeking_residual_boxplot.png}
		\centering
		\caption{The normalized residuals of the math model plotted for each of the 4 quantiles. }
		\label{fig::lm_math_nopeeking_boxplot}
	\end{figure}

	\begin{figure}
		\includegraphics[width=8cm]{lm_socst_nopeeking_residual_boxplot.png}
		\centering
		\caption{The normalized residuals of the math model plotted for each of the 4 quantiles. }
		\label{fig::lm_socst_nopeeking_boxplot}
	\end{figure}


	We also check for outliers by plotting the normalized residuals against the model's estimations. The red lines denote the $y=1.95$ and $y=-1.95$ values respectively and we expect 95\% of the points to be within them. Any value outside of $[-3,3]$ indicates a strong outlier which must be investigated. Figures \ref{fig::lm_math_plot}, \ref{fig::lm_socst_plot} show models including the writing scores. Figures \ref{fig::lm_math_nopeeking_plot}, \ref{fig::lm_sosct_nopeeking_plot} show models including only the other lesson's scores.
	
	 \begin{figure}
	 	\includegraphics[width=4cm]{lm_math_residual_plot.png}
	 	\centering
	 	\caption{The normalized residuals of the math model plotted against the model's estimations.}
	 	\label{fig::lm_math_plot}
	 \end{figure}
 
	 \begin{figure}
	 	\includegraphics[width=4cm]{lm_socst_residual_plot.png}
	 	\centering
	 	\caption{The normalized residuals of the social studies model plotted against the model's estimations. Notice the one outlier above the $y=3$ line, which represents the data point that was investigated and removed.}
	 	\label{fig::lm_socst_plot}
	 \end{figure}
 
	 \begin{figure}
	 	\includegraphics[width=4cm]{lm_math_nopeeking_residual_plot.png}
	 	\centering
	 	\caption{The normalized residuals of the math model plotted against the model's estimations. We notice three potential outliers. These values are considered non-anomalous, as they stray sufficiently away from the $y=3$ and $y=-3$ brackets, and are to be expected in a sample of 200 values.}
	 	\label{fig::lm_math_nopeeking_plot}
	 \end{figure}
 
	 \begin{figure}
	 	\includegraphics[width=4cm]{lm_socst_residual_plot.png}
	 	\centering
	 	\caption{The normalized residuals of the social studies model (without the writing scores variable) plotted against the model's estimations. We don't consider the values above and below the $y=3$ and $y=-3$ brackets respectively for the same reasons as in Figure \ref{fig::lm_math_nopeeking_plot}.}
	 	\label{fig::lm_sosct_nopeeking_plot}
	 \end{figure}
	
\end{document}